# Fit

**Training error**

The plots generated in e_noisy_parabolic_data.py give examples of training error - how well the model performs on the data from which it was learned.

Small training error is a necessary condition for a great model, but it is not sufficient.

We want the model to work well on other data generated by the same process, e.g.:

- measurements for other weights on the spring
- voters other than those surveyed.

**Cross-validation**

- Generate models using one dataset, then test using another.

- Use models for Dataset 1 to predict points for Dataset 2.
- Use models for Dataset 2 to predict points for Dataset 1.

- We expect testing error to be larger than training error.

- This provides a better indication of how much we can generalise the model.

**Wrap-up**

- We can use linear regression to fit a curve to data, mapping from independent values to dependent values.

- That curve is a model of the data that can be used to predict the value associated with independent values we haven't seen (outside of the sample data).

- R-squared can be used to evaluate the quality of fit of a model.
- But a higher R^2 is not always better, due to the risk of over-fitting.

- We should choose model complexity based on:

  - Theory about structure of data
  - Cross-validation
  - Simplicity.

- When in doubt, choose the simpler model.
